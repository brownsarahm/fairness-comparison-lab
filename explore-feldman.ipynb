{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore an Feldman Preprocessing\n",
    "\n",
    "run the cell below twice, the warning about missing Orange is just a warning and if you run again, it goes away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fairness import results\n",
    "from fairness.data.objects.list import DATASETS, get_dataset_names\n",
    "from fairness.data.objects.ProcessedData import ProcessedData\n",
    "from fairness.algorithms.list import ALGORITHMS\n",
    "from fairness.metrics.list import get_metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll look at the list of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = get_dataset_names()\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to choose just one of them to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ricci'\n",
    "dataset_idx = dataset_names.index(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You should now, rename this notebook to be `explore-<dataset name>`. Ideally, make a copy and rename that, then you can reuse the original to re-run on a different dataset easily\n",
    "\n",
    "Now, we can select the dataset object that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesed_dataset = ProcessedData(DATASETS[dataset_idx])\n",
    "single_sensitive = procesed_dataset.data.sensitive_attrs[0]\n",
    "class_attr = procesed_dataset.data.class_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feldman = ALGORITHMS[11]\n",
    "feldman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = procesed_dataset.dfs['original']\n",
    "repaired_df = feldman.repair(processed_df, single_sensitive, class_attr, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to add back the original protected attribute to be able to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_df['orig_' + single_sensitive] = processed_df[single_sensitive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can explore what has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the differences, to see how the values are distibributed.  We will se the `hue` to the protected class, so that we get different bars for each group, `col` to the target value of the prediction and plot a histogram of one of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(processed_df, col=\"Class\", hue=\"Race\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Combine',  ec=\"k\")\n",
    "g.axes[-1].legend(); #semicolon prevents extra output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(repaired_df, col=\"Class\", hue=\"orig_Race\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Combine',  ec=\"k\")\n",
    "g.axes[-1].legend(); #semicolon prevents extra output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to see how balanced (or imbalanced) the data is, so we will group by protected class and target variable and count the number of items for (any) one variable.  `unstack` changes the orientation fo the tabulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.groupby(['Race','Class'])['Position'].count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other ways can you analyze and try to understand what this fairness intervention is doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
